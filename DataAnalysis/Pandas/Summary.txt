-- Creating virtual envs --
    conda create -n "myenv" python=3.9
    pip install pandas




-- Setting rows / columns display --
pd.set_option('max_columns', None)
pd.set_option('max_columns', 2)
pd.set_option("max_rows", None)
pd.set_option("max_rows", 2)






import pandas as pd
df = pd.read_csv("../datasets/survey_results_public.csv")
df = pd.read_csv(<file_path>, index_col=<col_name>)

df.head(5) # show top 5 records
df.tail(5) # show last 5 records

df.shape # show (rows, cols)
df.info() # show columns, no. of non-null data, dtype of column
df.dtypes # show datatypes of columns







-- Creating DataFrames -- (2D Data structure)
    - table containing rows & cols of data
        - row: record
        - col: fields 

    data = {
        "col1": [1,2,3],
        "col2":[4,5,6],
        "col3":[7,8,9]
    }

    df = pd.DataFrame(data)




-- Series --
- 1-D dataframe having own series method
    





-- Manipulating columns --

df['col1'] # access col 1 of data as series
df.col1 # also valid, provided <col> no whitespaces / not method name

df[['col1', 'col2']] # access multiple columns (as DF)

df.columns # get column names






== Manipulating Rows ==
    * getting certain row records

    - using loc & iloc
        - iloc uses index
        - loc searches by labels 

    df.iloc[0] # gives 1st row data as panda series
    df.iloc[[0, 1]] # gives 1st 2 rows of data

    df.iloc[[0,1], 0] # gives 1st column data instead of row 
        - 1 for 2nd columns etc.

* If index is not string, loc behaves like iloc
df.loc[0] # return 1st row data
df.loc[[0,1]] returns 1st 2 row data

* if index is string (eg. email / full_name):
    - can still use iloc to pass integer as rows (by default first row is 0)

    df.loc['lucasleow@gmail.com'] # return all rows that have index lucasleow@gmail.com
    df.loc["lucasleow"]
    df.loc["lucasleow", <col>]
    df.loc['I am a developer by profession',['Age', 'RemoteWork']]
        - search by index, return Age & RemoteWork col


df.loc[0, 'col1'] # get 1st row data for that given column (single output)
df.loc[[0,1], 'col3'] # get first 2 row data from "col3"
df.loc[[0,1], ['col1', 'col3']] # get first 2 row data from col1 & col3

df.loc[0:2] # show first 3 row of data
df.loc[0:2,  'col1'] #slicing data, get first 3 data from 'col1'

df.loc[0:2, 'col1':'col3']

df['Hobbyist'].value_counts() # provide count for categorical data






== Manipulating Indexes ==
    - typically should be unique value as identifier for each row
    - not enforced by pandas

    df.set_index(<col_name>)
    df.set_index('email', inplace=True) 
        - by default, pandas dont set inplace for ppl to experiment

    df.index
    list(df.index)
        - provides object of all index values

    df.reset_index(inplace=True)
    df.sort_index() # more useful for alphabetical indexes
    df.sort_index(ascending=False, inplace=True)





== Filtering Data ==
    - getting data based on specific conditions


    Technique 1:
        1) Setup Filter Mask
            - conditions that return true / false
            filt = (df['last'] == 'Doe')
            filt = (df['last'] == 'Doe') & (df['first'] == 'John')
            filt = (df['last'] == 'Doe') | (df['first'] == 'John')

        2) Apply filter mask to DF (multiple ways to do it)
            2.1) df[filt]

            2.2) df.loc[filt]
                df.loc[filt, <col_name>]
                df.loc[filt, [<col1>, <col2>]]
                df.loc[~filt, <col1>]
                    - ~ means not

                high_salary_filt = (df['salary] > 70000)
                df.loc[high_salary_filt, ['Country', 'LanguageWorkedWith', 'Salary']]

            2.3) df[df['last'] == 'Doe']



    Technique 2:
        countries = ['United States', 'India', 'United Kingdom']
        filt = df['country'].isin(countries)
        df.loc[filt, 'country']



    Technique 3:

            filt = df['LanguageWorkedWith].str.contains('Python', na=False)
                - for the column <LanguageWorkedWith>
                - if 'Python' within this column, then return true
                - na=False: Replace na values with False

                "HTML/CSS;Java;JavaScript;Python"





== Update Row & Column Data + Add new data ==
    df.columns # print all col names


    - Renaming column name

                    df.columns = ['first', 'last', 'email']
                        - must pass name for all columns
                    
                    df.columns = [x.upper() for x in df.columns]

                    df. columns = df.columns.str.replace(' ', '_')
                        - replace all column name with space to _
                    
                    df.rename(columns={<old_col>:<new_col>, <old2>:<new2>}, inplace = True)




    - Updating single row
                
                        df.loc[2] = ['John', 'Smith', 'JohnSmith@email.com']
                            - need to pass in all values for all cols
                        
                        df.loc[2, ['first', 'last']] = ['John', 'Doe']
                            - only change 'first' & 'last' col by providing the value

                        df.loc[2, 'last'] = 'Smith'
                            - to change single value of 'last' col

                        df.at[2, <col_name>] = 'Tom'
                            - also works similarly to loc




    - Updating multiple row of data

                df['email'] = df['email'].str.lower()

                Techniques (multiple ways to update multiple row of data)
                    - apply
                    - map
                    - applymap
                    - replace



            Technique 1: apply
                - can work on DF or Series obj

                For Series:

                            df['email'].apply(len) #print out the len of each row


                            def update_email(email):
                                return email.upper()
                            
                            df['email'] = df['email'].apply(update_email)

                            

                            df['email'] = df['email'].apply(lambda x: x.lower())
            
                For DataFrame:
                    - apply function to each series in the dataframe
                    - series aka column of data

                            df.apply(pd.Series.min)
                                - returns the min value for each column in DF

                            df.apply(lambda x: x.min())
                                - works similar to above using lambda function



            Technique 2: applymap
                - apply only on each Series (col) of DataFrame
                - applymap on each value of DataFrame
                - will only work on DataFrame

                        df.applymap(len)
                            - provides DF of len of each value in DF
                             - throws error if numerical values exists
                        
                        df.applymap(str.lower)
                            - all values change to lowercase
                            - throws error if numerical values exists



            Technique 3: map
                - only works on Series obj
                df['first'] = df['first'].map({'Corey':'Chris', 'Jane':'Mary'})
                    - converts all Corey into Chris & Jane into Mary
                    - if nonconverted, will change to NaN
                    - if dont want NaN, just use replace method


                df['Hobbyist'] = df['Hobbyist'].map({'Yes': True, 'No': False})
                    - converts 'Yes' to True & 'No' to False
                    - if no values specified, will change to NaN
                    - if dont want to convert to NaN, use replace



            Technique 4: replace
                - same as map but does not convert non-filter value into NaN
                - only works on Series

                df['first'] = df['first'].replace({'Corey':'Chris', 'Jane':'Mary'})


            
